{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 데이터사이언스개론 </center>\n",
    "## <center> Classification 실습 과제 </center>\n",
    "\n",
    "<div class=\"pull-right\"> 컴퓨터공학과 201811259 배수빈 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. Classification 알고리즘 요약정리    \n",
    "1-1. SVM 알고리즘   \n",
    "1-2. Logistic Regression 알고리즘    \n",
    "1-3. Random Forest 알고리즘    \n",
    "2. db_score_3_labels.xlsx 파일 테이블로 구축    \n",
    "3. grade B에 대한 binary classification    \n",
    "3-0-1. DB에서 불러오기    \n",
    "3-0-2. 정확도 측정 함수    \n",
    "3-1. X데이터와 Y데이터 구분   \n",
    "3-2-1. test, train 데이터 분류 - train_test_split   \n",
    "3-2-1-1. SVM모델 ( train_test_split )   \n",
    "3-2-1-2. Logistic Regression 모델 ( train_test_split )   \n",
    "3-2-1-3. Random Forest 모델 ( train_test_split )   \n",
    "3-2-2. test, train 데이터 분류 - KFold cross validation   \n",
    "3-2-2-1. SVM모델 ( KFold cross validation )    \n",
    "3-2-2-2. Logistic Regression 모델 ( KFold cross validation )    \n",
    "3-2-2-3. Random Forest 모델 ( KFold cross validation )    \n",
    "4. grade A,B,C에 대한 multi-class classification    \n",
    "4-0. 정확도 측정 함수    \n",
    "4-1. X데이터와 Y데이터 구분   \n",
    "4-2-1. test, train 데이터 분류 - train_test_split   \n",
    "4-2-1-1. SVM모델 ( train_test_split )   \n",
    "4-2-1-2. Logistic Regression 모델 ( train_test_split )   \n",
    "4-2-1-3. Random Forest 모델 ( train_test_split )   \n",
    "4-2-2. test, train 데이터 분류 - KFold cross validation   \n",
    "4-2-2-1. SVM모델 ( KFold cross validation )   \n",
    "4-2-2-2. Logistic Regression 모델 ( KFold cross validation )   \n",
    "4-2-2-3. Random Forest 모델 ( KFold cross validation )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 1. Classification 알고리즘 요약정리 \n",
    "### 1-1. SVM 알고리즘 \n",
    "   \n",
    "\n",
    "##### * SVM ( Support Vector Machines ) 이란?\n",
    "- 패턴 인식, 자료 분석을 위한 지도 학습 모델 ( 주로 분류/ 회귀 분석을 위해 사용 )\n",
    "- 두 카테고리 중 어느 하나에 속한 데이터의 집합이 주어졌을 때, 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적 이진 선형 분류 모델을 만듦\n",
    "- 쉽게 말해 **결정 경계**(분류를 위한 기준 선)를 정의하는 모델. 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류하는 과제를 수행\n",
    "\n",
    "|2개의 카테고리 |3개의 카테고리 |\n",
    "|:---:|:---:|\n",
    "|![](https://i0.wp.com/hleecaster.com/wp-content/uploads/2020/01/svm01.png)|![](https://i0.wp.com/hleecaster.com/wp-content/uploads/2020/01/svm02.png)|\n",
    "| 카테고리가 2가지일 경우 결정 경계는 간단한 선 형태 | 카테고리가 3가지일 경우 3차원으로 표현되며, 결정 경계는 선이 아닌 평면 형태 |\n",
    "\n",
    "- 우리가 시각적으로 인지할 수 있는 범위는 3차원까지이지만, 카테고리의 갯수가 늘어날수록 결정경계와 데이터가 존재하는 공간이 고차원이 될 것  \n",
    "     => 이를 **초평면**(hyperplain) 이라고 부름 \n",
    "   \n",
    "\n",
    "##### * 최적의 결정 경계  란?\n",
    "결정경계는 무수히 많이 그을 수 있는데, 그중 가장 좋은 경계는?\n",
    "![](https://i1.wp.com/hleecaster.com/wp-content/uploads/2020/01/svm03.png?resize=768%2C576)\n",
    "위의 그림에서  \n",
    "C의 경우 선이 파란색 부류와 너무 가까움\n",
    "F의 경우 선이 두 클래스 사이에서 거리가 가장 멀기 때문에 가장 적절해보임   \n",
    "==> 결정경계는 ***데이터 군으로부터 최대한 멀리 떨어지는 것***이 좋다!\n",
    "  \n",
    "\n",
    "##### * 마진 이란?\n",
    "마진(Margin) = 결정 경계와 서포트 벡터 사이의 거리\n",
    "![](https://i0.wp.com/hleecaster.com/wp-content/uploads/2020/01/svm04.png?resize=768%2C576)\n",
    "( Support Vectors = 결정 경계와 가까이 있는 데이터 포인트들 )   \n",
    "위의 그림에서   \n",
    "결정 경계 : 가운데 실선   \n",
    "Support Vectors : 검은 테두리가 있는 빨간점 1개, 파란점 2개   \n",
    "마진 : 그림에서의 점선으로부터 결정 경계(실선)까지의 거리  \n",
    "==> ***최적의 결정 경계는 마진을 최대화한다.***  \n",
    "\n",
    "x축과 y축 2개의 속성을 가진 데이터로 결정 경계를 그었는데, 총 3개의 서포트 벡터가 필요했음 \n",
    "==> ***n개의 속성을 가진 데이터에는 최소 n+1개의 서포트 벡터가 존재한다.***   \n",
    "\n",
    "##### * SVM 알고리즘의 장점 \n",
    "- 결정 경계를 정의하는게 서포트 벡터이기 때문에 데이터 포인트 중에서 서포트 벡터만 잘 골라내면, 나머지의 수많은 쓸데 없는 데이터 포인트들을 무시할 수 있어 빠르다. \n",
    "\n",
    "[출처] \"아무튼워라밸\" http://hleecaster.com/ml-svm-concept/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 1-2. Logistic Regression 알고리즘 \n",
    "\n",
    "##### * Logistic Regression 이란?\n",
    "- 회귀를 사용해서 데이터가 어떤 범주에 속할 확률을 0에서 1사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도학습 알고리즘\n",
    "- 예를 들어 확률이 0.5이상일 경우 A로 분류 / 0.5보다 작을 경우 B로 분류 \n",
    "\n",
    "Ex). 공부시간에 따른 시험 합격 확률\n",
    "\n",
    "|선형회귀 방법 |로지스틱회귀 방법 |\n",
    "|:---:|:---:|\n",
    "|![](https://i1.wp.com/hleecaster.com/wp-content/uploads/2019/12/logreg01.png?w=1017)|![](https://i0.wp.com/hleecaster.com/wp-content/uploads/2019/12/logreg02.png?w=973)|\n",
    "| 공부시간이 적으면 시험에 통과X, 공부시간이 많으면 시험에 통과로 설명가능/ But **확률이 음과 양의 방향으로 무한대까지 뻗어감** ( 0, 1 사이가 아닐 경우 확률로 따질 수 없음 ) | 확률이 **0과 1사이의 값**으로 그려짐  |\n",
    "\n",
    "위와 같은 예시로 로지스틱 회귀에서는 데이터가 특정 범주에 속할 확률을 예측하기 위해 다음과 같은 단계를 거침\n",
    "1. 모든 속성들의 계수와 절편을 0으로 초기화\n",
    "2. 각 속성들의 값에 계수를 곱해서 log-odds를 구함\n",
    "3. log-odds를 sigmoid함수에 넣어서 [0, 1] 범위의 확률을 구함\n",
    "\n",
    "##### *Log-Odds 란?\n",
    "\n",
    "선형회귀에서는 각 속성의 값에다가 계수를 곱하고 절편을 더해서 예측값을 구함   \n",
    "그래서 구한 예측 값의 범위는 -∞에서 + ∞\n",
    "로지스틱 회귀에서는 예측값의 범위를 [0, 1]로 하기 위해서 log-odds를 구해야함  \n",
    "\n",
    "우선 Odds는 '실패에 비해 성공할 확률의 비'로   \n",
    "시험에 합격할 확률이 0.7일 경우   \n",
    "Odds = 0.7/0.3 = 2.33 이다. \n",
    "\n",
    "이렇게 구한 Odds에 log를 취한 것이 바로 log-odds\n",
    "LogOdds = log(2.33) = 0.847\n",
    "\n",
    "**<계산>**   \n",
    "로지스틱 회귀에서는 여러 속성들에 계수를 곱하고 절편을 더해서 log-odds를 구해야 하기  때문에 까다로움  \n",
    "***z = b0 + b1x2 + b2x2 + ... + bnxn***\n",
    "그래서 로지스틱 회귀에서는 '내적'을 통해서 log-odds를 구함\n",
    "\n",
    "밑의 그림에서 초록색과 노란색의 숫자가 속성들의 값이고, 보라색과 빨간색의 값이 그 속성들 각각의 계수\n",
    "![](https://i0.wp.com/hleecaster.com/wp-content/uploads/2019/12/logreg07.png?w=569)\n",
    "연산은 다음과 같이 numpy의 np.dot()으로 쉽게 할 수 있음\n",
    "```python\n",
    "log_odds = np.dot(features, coefficients) + intercept\n",
    "```\n",
    "\n",
    "##### *Sigmoid Function 이란?\n",
    "\n",
    "로지스틱 회위에서 확률을 0에서 1사이로 커브 모양으로 나타내야 하는데, 이를 Sigmoid함수가 수행함. 함수는 다음과 같다. \n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/faaa0c014ae28ac67db5c49b3f3e8b08415a3f2b)\n",
    "\n",
    "##### *Classification Threshold (임계값 )\n",
    "\n",
    "로지스틱 회귀 알고리즘의 결과값은 분류 확률로 이 확률이 특정 수준 이상 확보되면 샘플이 그 클래스에 속할지 말지 결정할 수 있음. 따라서 대부분의 알고리즘의 경우 기본 임계값은 0.5    \n",
    "   \n",
    "다만, 필요에 따라 모델의 임계값을 변경할 수 있음.   \n",
    "임계값을 0.3이나 0.4로 낮춤 => 민감도 높아짐     \n",
    "==> 오분류가 많아지더라도 실제로 그 분류에 속하는 값들은 확실히 맞출 수 있음 \n",
    "\n",
    "Ex). 암 진단 로지스틱 회귀 모델    \n",
    "아래의 그림에서  \n",
    "빨간색으로 칠해진 부분은 실제 암발병X, 암으로 예측됨    \n",
    "노란색으로 칠해진 부분은 실제 암발병O, 암으로 예측되지 않음 \n",
    "\n",
    "|임계값 = 0.5 | 임계값 = 0.4 |\n",
    "|:---:|:---:|\n",
    "|![](https://i2.wp.com/hleecaster.com/wp-content/uploads/2019/12/logreg13.png?w=1115)|![](https://i2.wp.com/hleecaster.com/wp-content/uploads/2019/12/logreg14.png?w=1115)|\n",
    "| 오분류 적음 / 노란색부분 넓음 | 오분류 많음 / 노란색부분 좁음 |\n",
    "\n",
    "해당 경우에서는 실제로 암에 걸린 환자가 암으로 예측되지 않는 경우가 적어야함.  \n",
    "임계값이 작은 0.4에서 노란색 부분이 좁은 것으로 보아 암 진단 모델에서의 임계값은 0.5보다 0.4가 더 적합하다. \n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "[출처] \"아무튼워라밸\" http://hleecaster.com/ml-logistic-regression-concept/   \n",
    "[출처] \"ratsgo's blog\" https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 1-3. Random Forest 알고리즘 \n",
    "\n",
    "\n",
    "##### * Random Forest 란?\n",
    "- 조금씩 다른 열개의 의사결정트리의 묶음 (앙상블 학습법)\n",
    "- 의사결정트리가 훈련데이터에 오버피팅되는 단점을, 여러개의 의사결정트리를 사용해서 해결\n",
    "- 앙상블 학습법 (여러개의 모델을 학습시켜 각 모델의 결과를 합치는 방식 )    \n",
    "\n",
    "Ex). 건강위험도를 파악하는 Random Forest를 만드는 과정   \n",
    "\n",
    "*위협도 예측 요소(fature ) 30개로 가정*  \n",
    "( 성별, 키, 몸무게, 지역, 운동량, 흡연유무, 음주 여부, 혈당 등등 )\n",
    "  \n",
    "1. 랜덤으로 4개의 feature만 선택해서 하나의 의사결정트리 만듦 \n",
    "2. 반복해서 여러개의 의사결정트리 만듦 \n",
    "3. 의사 결정 트리마다 내놓는 예측값중 다수결의 원칙에 따라 최종 예측값 결정\n",
    "\n",
    "##### * Random Forest 시각화\n",
    "\n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHJ2u4%2Fbtqw2kmJhgO%2FW89tIKkvKNuUa9islCuTU1%2Fimg.png)\n",
    "\n",
    "오늘쪽 아래가 랜덤 포레스트의 Decesion Boundary    \n",
    "나머지는 각 의사결정트리의 Decision Boundary ( 경계 모호, 오버피팅됨 )\n",
    "\n",
    "[출처] \"귀통이 서재\" https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-5-%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8Random-Forest%EC%99%80-%EC%95%99%EC%83%81%EB%B8%94Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  2. db_score_3_labels.xlsx 파일 테이블로 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_score_data():\n",
    "    file = 'db_score_3_labels.xlsx'\n",
    "    score = pd.read_excel(file) \n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', user = 'root', password = 'dbsrl9339^^', db = 'university')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "\n",
    "    drop_sql = \"\"\"drop table if exists score\"\"\"\n",
    "    \n",
    "    import sqlalchemy\n",
    "    database_username = 'root'\n",
    "    database_password = 'dbsrl9339^^'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'score'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format(database_username, database_password, \n",
    "                                                                                             database_ip, database_name))\n",
    "    score.to_sql(con = database_connection, name = 'score', if_exists = 'replace')\n",
    "                                                                                            \n",
    "load_score_data()                                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 엑셀파일을 읽어 sql의 테이블로 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "##  3. grade B에 대한 binary classification \n",
    "* scikit learn 사용할것  \n",
    "* train_test_split 과 K-fold cross validation 을 통한 4가시 정능 제시할것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-0-1. DB에서 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "conn = pymysql.connect(host='localhost', user = 'root', password = 'dbsrl9339^^', db = 'score')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from score\" \n",
    "curs.execute(sql)\n",
    "\n",
    "data = curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- curs.execute( 쿼리문 ) 을 통해서 쿼리문을 DB서버에 보냄\n",
    "- 커서객체의 fetchall() 메소드를 통해서 데이터를 서버로부터 가져옴 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-0-2. 정확도 측정 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def classification_performance_eval(y, y_predict):\n",
    "    \n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y, yp in zip(y, y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1\n",
    "        elif y == -1 and yp == 1:\n",
    "            fp += 1\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1\n",
    "\n",
    "    try: \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        accuracy = 0\n",
    "       \n",
    "    try: \n",
    "        precision = (tp)/(tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "        \n",
    "    try: \n",
    "        recall = (tp)/(tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "        \n",
    "    try: \n",
    "        f1_score = (2*precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1_score = 0\n",
    " \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F99DC064C5BE056CE106BC1) \n",
    "- tp와, fn, fp, tn은 위의 표와 같은 조건에 의해서 값이 설정되도록 반복문 실행\n",
    "- accuracy와 precision, recall, f1_score은 각각에 식에 의해 계산됨\n",
    "- 계산 과정 중에서 분모에 대입될 숫자가 0일 경우, 계산이 불가능하므로, 해당 값이 0으로 대입되도록 하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. X데이터와 Y데이터 구분\n",
    "X (feature 값) : homework, discussion, midterm  \n",
    "Y (Label값) : grade  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ (t['homework'], t['discussion'], t['midterm']) for t in data]\n",
    "X = np.array(X) \n",
    "  \n",
    "Y = [ 1 if(t['grade'] == 'B') else -1 for t in data ]\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data ( 딕셔너리의 리스트 타입 ) 에서 하나의 딕셔너리를 꺼내 필요한 컬럼값만 참조해서 해당 값을 X리스트에  리스트 형태로 저장한다. \n",
    "- 마찬가지의 방법으로 'grade'의 값이 'B'일 경우 Y 리스트에 튜플형태로 저장한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-1. test, train 데이터 분류 - train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(Y_test)\n",
    "#Y값이 잘 섞여 있는 것을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split** :    \n",
    "특정 비율로 Train데이터와 Test데이터를 나눠줌\n",
    "\n",
    "\n",
    "- 값을 랜덤한 순서로 33퍼센트의 데이터만 X_test와 Y_test에 저장함\n",
    "- X_train에 대응하는 Y값은 Y_train에 저장됨\n",
    "- X_test에 대응하는 Y값은 Y_test에 저장됨\n",
    "- Y_test의 출력값을 보면, 1과 -1이 섞여나오는 것으로 보아, 랜덤한 순서로 잘 섞인 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-1-1. SVM모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.7096774193548387\n",
      "precision =  0\n",
      "recall =  0.0\n",
      "f1_score =  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM_model = SVM.fit(X_train, Y_train)\n",
    "Y_predict = SVM_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "print(\"accuracy = \", acc)\n",
    "print(\"precision = \", prec)\n",
    "print(\"recall = \", rec)\n",
    "print(\"f1_score = \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn라이브러리에서 SVM알고리즘을 활용할 수 있는 SVC를 import하여 활용\n",
    "- SVC에 X_train와 Y_train으로 모델을 학습시킴\n",
    "- 학습된 SVM_model을 통해서 X_test의 Y값들을 예측함 (Y_predict)\n",
    "- Y_test (실제 X_test에 대응되는 값) 과 Y_predict(예측값) 을 비교하여 정확도 계산 (3-0-2에서 선언한 classification_performance_eval 함수 활용 )\n",
    "\n",
    "*정확도* :    \n",
    "accuracy는 계산되지만, precision과 f1_score의 값은 0으로 나뉘어 계산함수에서 0으로 대입된것으로 보임   \n",
    "recall은 0의 정확도이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-1-2. Logistic Regression 모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.6774193548387096\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1_score =  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR_model = LR.fit(X_train, Y_train)\n",
    "Y_predict = LR_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "print(\"accuracy = \", acc)\n",
    "print(\"precision = \", prec)\n",
    "print(\"recall = \", rec)\n",
    "print(\"f1_score = \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn라이브러리에서 선형회귀 알고리즘을 활용할 수 있는 LogisticRegression를 import하여 활용\n",
    "- LRmodel에 X_train와 Y_train으로 모델을 학습시킴\n",
    "- 학습된 LRmodel을 통해서 X_test의 Y값들을 예측함 (Y_predict)\n",
    "- Y_test (실제 X_test에 대응되는 값) 과 Y_predict(예측값) 을 비교하여 정확도 계산 (3-0-2에서 선언한 classification_performance_eval 함수 활용 )\n",
    "\n",
    "*정확도* :    \n",
    "accuracy는 계산되지만, precision과 f1_score의 값은 0으로 나뉘어 계산함수에서 0으로 대입된것으로 보임   \n",
    "recall은 0의 정확도이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-1-3. Random Forest 모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.6129032258064516\n",
      "precision =  0.2857142857142857\n",
      "recall =  0.2222222222222222\n",
      "f1_score =  0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(criterion = 'entropy', n_estimators = 10, n_jobs=2, random_state = 1)\n",
    "RF_model = RF.fit(X_train, Y_train)\n",
    "Y_predict = RF_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "print(\"accuracy = \", acc)\n",
    "print(\"precision = \", prec)\n",
    "print(\"recall = \", rec)\n",
    "print(\"f1_score = \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn라이브러리에서 랜덤포레스트 알고리즘을 활용할 수 있는 RandomForestClassifier를 import하여 활용\n",
    "- RF_model에 X_train와 Y_train으로 모델을 학습시킴\n",
    "- 학습된 RF_model을 통해서 X_test의 Y값들을 예측함 (Y_predict)\n",
    "- Y_test (실제 X_test에 대응되는 값) 과 Y_predict(예측값) 을 비교하여 정확도 계산 (3-0-2에서 선언한 classification_performance_eval 함수 활용 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-2. test, train 데이터 분류 - KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "def list_free() : \n",
    "    accuracy.clear()\n",
    "    precision.clear()\n",
    "    recall.clear()\n",
    "    f1_score.clear()\n",
    "\n",
    "kf = KFold( n_splits = 5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KFold cross validation** :    \n",
    "데이터를 특정 갯수만큼의 부분 집합으로 분할한 수, 각 분할마다 하나의 폴드를 test용으로 사용, 나머지를 train용으로 사용   \n",
    "\n",
    "\n",
    "- 각각의 집합에서의 정확도의 평균을 전체 데이터셋에 대한 정확도로 하기 위해서 가가 정확도를 저장할 리스트를 선언해둠 \n",
    "- list_free() :    \n",
    "아래에서 모델별로 선언해둔 리스트 변수를 재활용하기 때문에, 각 모델의 정확도를 측정해서 저장하기 전에, 각 리스트를 비워주기 위함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-2-1. SVM모델 ( KFold cross validation ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.435673\n",
      "average_precision = 0.113333\n",
      "average_recall = 0.073333\n",
      "average_f1_score = 0.086667\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "    \n",
    "import statistics\n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print(\"average_precision = %f\" %statistics.mean(precision))\n",
    "print(\"average_recall = %f\" %statistics.mean(recall))\n",
    "print(\"average_f1_score = %f\" %statistics.mean(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-2-2. Logistic Regression 모델 ( KFold cross validation ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.563743\n",
      "average_precision = 0.040000\n",
      "average_recall = 0.066667\n",
      "average_f1_score = 0.050000\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    LR = LogisticRegression()\n",
    "    LR_model = LR.fit(X_train, Y_train)\n",
    "    Y_predict = LR_model.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "import statistics\n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print(\"average_precision = %f\" %statistics.mean(precision))\n",
    "print(\"average_recall = %f\" %statistics.mean(recall))\n",
    "print(\"average_f1_score = %f\" %statistics.mean(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2-2-3. Random Forest 모델 ( KFold cross validation ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.683041\n",
      "average_precision = 0.604286\n",
      "average_recall = 0.374286\n",
      "average_f1_score = 0.421737\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    RF = RandomForestClassifier(criterion = 'entropy', n_estimators = 10, n_jobs=2, random_state = 1)\n",
    "    RF_model = RF.fit(X_train, Y_train)\n",
    "    Y_predict = RF_model.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "import statistics\n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print(\"average_precision = %f\" %statistics.mean(precision))\n",
    "print(\"average_recall = %f\" %statistics.mean(recall))\n",
    "print(\"average_f1_score = %f\" %statistics.mean(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "##  4. grade A,B,C에 대한 multi-class classification \n",
    "* scikit learn 사용할것  \n",
    "* train_test_split 과 K-fold cross validation 을 통한 4가시 정능 제시할것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-0. 정확도 측정 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "def classification_performance_eval(y, y_predict):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    from sklearn import metrics\n",
    "    matrix = metrics.confusion_matrix(Y_test, Y_predict)  \n",
    "\n",
    "    for i in range(3):\n",
    "        try: \n",
    "            precision.append(matrix[i,i]/ sum(matrix)[i] )\n",
    "        except ZeroDivisionError:\n",
    "            precision.append(0)\n",
    "        \n",
    "        try: \n",
    "            temp = matrix[i, 0] + matrix[i, 1] + matrix[i,2]\n",
    "            recall.append(matrix[i, i] / temp)\n",
    "        except ZeroDivisionError:\n",
    "            recall.append(0)\n",
    "        \n",
    "        try: \n",
    "            f1_score.append(2*precision[i]*recall[i] / (precision[i] + recall[i]))\n",
    "        except ZeroDivisionError:\n",
    "            f1_score.append(0)\n",
    "            \n",
    "    try: \n",
    "        accuracy = (matrix[0,0]+matrix[1,1]+ matrix[2,2]) / np.sum(matrix)\n",
    "    except ZeroDivisionError:\n",
    "        accuracy = 0\n",
    "\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "import statistics\n",
    "def kfold_mean(prec, rec, f1):\n",
    "    prec_np = np.array(prec)\n",
    "    rec_np = np.array(rec)\n",
    "    f1_np = np.array(f1)\n",
    "                \n",
    "    prec_mean = [ statistics.mean(prec_np[0:5, 0]), \n",
    "                 statistics.mean(prec_np[0:5, 1]),\n",
    "                 statistics.mean(prec_np[0:5, 2]) ]\n",
    "    rec_mean = [ statistics.mean(rec_np[0:5, 0]), \n",
    "                 statistics.mean(rec_np[0:5, 1]),\n",
    "                 statistics.mean(rec_np[0:5, 2]) ]\n",
    "    f1_mean = [ statistics.mean(f1_np[0:5, 0]), \n",
    "                 statistics.mean(f1_np[0:5, 1]),\n",
    "                 statistics.mean(f1_np[0:5, 2]) ]\n",
    "    df = pd.DataFrame({\"precision\" : prec_mean , \n",
    "                   \"recall\" : rec_mean , \n",
    "                   \"f1_score\" : f1_mean},\n",
    "                  index = ['A', 'B', 'C'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi class Classification에서의 confusion matrix :\n",
    "![](https://www.researchgate.net/profile/Alaa_Tharwat/publication/327148996/figure/fig2/AS:700752393670660@1544083798963/An-illustrative-example-of-the-confusion-matrix-for-a-multi-class-classification-test.png)\n",
    "\n",
    "- 해당 코드에서 matrix또한 위의 표처럼 대입되어있음    \n",
    "\n",
    "#### classification_performance_eval() :\n",
    "- 각각의 값(A, B, C)에 대해서 모두 precision과 recall, f1_score를 계산\n",
    "- 내부의 for문이 3번 반복 - i가 0인 루프가 실행될때는 A에 대해서 계산하고 1일 때는 B, 2일때는 C에 대해서 계산함\n",
    "\n",
    "#### kfold_mean() :\n",
    "- kfold cross validation의 방식으로 test데이터와 train데이터를 구분할 경우 각 묶음의 데이터셋에 대해서 A, B, C의 정확도들이 저장되어있음 \n",
    "- 이때 이 각각의 데이터셋에 대해서 정확도의 평균을 내는 함수\n",
    "- 데이터프레임 형태(행과 열에 각각 A, B, C/ precision, recall, f1_score )로 정확도를 리턴함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. X데이터와 Y데이터 구분\n",
    "X (feature 값) : homework, discussion, midterm  \n",
    "Y (Label값) : grade  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ (t['homework'], t['discussion'], t['midterm']) for t in data]\n",
    "X = np.array(X) \n",
    "Y = []\n",
    "\n",
    "for t in data :\n",
    "    Y.append(t['grade'])\n",
    "\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-1. test, train 데이터 분류 - train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-1-1. SVM모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.5806451612903226\n",
      "   precision    recall  f1_score\n",
      "A   0.583333  0.636364  0.608696\n",
      "B   0.333333  0.444444  0.380952\n",
      "C   1.000000  0.636364  0.777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM_model = SVM.fit(X_train, Y_train)\n",
    "Y_predict = SVM_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "\n",
    "df = pd.DataFrame({\"precision\" : prec , \n",
    "                   \"recall\" : rec , \n",
    "                   \"f1_score\" : f1},\n",
    "                  index = ['A', 'B', 'C'])\n",
    "print(\"accuracy = \", acc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-1-2. Logistic Regression 모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.5806451612903226\n",
      "   precision    recall  f1_score\n",
      "A   0.583333  0.636364  0.608696\n",
      "B   0.333333  0.333333  0.333333\n",
      "C   0.800000  0.727273  0.761905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR_model = LR.fit(X_train, Y_train)\n",
    "Y_predict = LR_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "\n",
    "df = pd.DataFrame({\"precision\" : prec , \n",
    "                   \"recall\" : rec , \n",
    "                   \"f1_score\" : f1},\n",
    "                  index = ['A', 'B', 'C'])\n",
    "print(\"accuracy = \", acc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-1-3. Random Forest 모델 ( train_test_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.6129032258064516\n",
      "   precision    recall  f1_score\n",
      "A   0.636364  0.636364  0.636364\n",
      "B   0.375000  0.333333  0.352941\n",
      "C   0.750000  0.818182  0.782609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(criterion = 'entropy', n_estimators = 10, n_jobs=2, random_state = 1)\n",
    "RF_model = RF.fit(X_train, Y_train)\n",
    "Y_predict = RF_model.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "df = pd.DataFrame({\"precision\" : prec , \n",
    "                   \"recall\" : rec , \n",
    "                   \"f1_score\" : f1},\n",
    "                  index = ['A', 'B', 'C'])\n",
    "print(\"accuracy = \", acc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-2. test, train 데이터 분류 - KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "accuracy = []\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "f1_list = []\n",
    "\n",
    "def list_free() : \n",
    "    accuracy.clear()\n",
    "    prec_list.clear()\n",
    "    rec_list.clear()\n",
    "    f1_list.clear()\n",
    "\n",
    "kf = KFold( n_splits = 5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-2-1. SVM모델 ( KFold cross validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.587719\n",
      "\n",
      "   precision    recall  f1_score\n",
      "A   0.600000       NaN       NaN\n",
      "B   0.425476  0.490476  0.419634\n",
      "C   0.811667  0.697857  0.749048\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    SVM = SVC(kernel='linear')\n",
    "    SVM_model = SVM.fit(X_train, Y_train)\n",
    "    Y_predict = SVM_model.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print()\n",
    "print(kfold_mean(prec_list, rec_list, f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-2-2. Logistic Regression 모델 ( KFold cross validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.663158\n",
      "\n",
      "   precision    recall  f1_score\n",
      "A   0.637857       NaN       NaN\n",
      "B   0.527619  0.607619  0.534841\n",
      "C   0.829762  0.766429  0.789661\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    LR = LogisticRegression()\n",
    "    LR_model = LR.fit(X_train, Y_train)\n",
    "    Y_predict = LR_model.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print()\n",
    "print(kfold_mean(prec_list, rec_list, f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-2-3. Random Forest 모델 ( KFold cross validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy = 0.629825\n",
      "\n",
      "   precision    recall  f1_score\n",
      "A   0.552424       NaN       NaN\n",
      "B   0.608810  0.469524  0.452698\n",
      "C   0.797619  0.828333  0.806111\n"
     ]
    }
   ],
   "source": [
    "list_free()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    RF = RandomForestClassifier(criterion = 'entropy', n_estimators = 10, n_jobs=2, random_state = 1)\n",
    "    RF_model = RF.fit(X_train, Y_train)\n",
    "    Y_predict = RF_model.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(Y_test, Y_predict)\n",
    "    accuracy.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "print(\"average_accuracy = %f\" %statistics.mean(accuracy))\n",
    "print()\n",
    "print(kfold_mean(prec_list, rec_list, f1_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
